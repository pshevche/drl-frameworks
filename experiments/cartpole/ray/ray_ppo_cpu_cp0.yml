ray_ppo_cpu_cp0:
  run: PPO
  env: CartPole-v0
  local_dir: "results/cartpole"  
  checkpoint_freq: 0
  checkpoint_at_end: False 
  agent_training_steps: 1000
  agent_evaluation_steps: 1000
  # number of iterations
  stop:
    training_iteration: 500
  # all other hyperparameters 
  config:
    # we want to evaluate manually, but still need the evaluator
    evaluation_interval: 1000000
    lr: 0.001
    num_workers: 0
    train_batch_size: 128
